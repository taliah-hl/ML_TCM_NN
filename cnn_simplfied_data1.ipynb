{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use simplified data 1\n",
    "\n",
    "data source: ./simplified_data/simplified_1.csv\n",
    "\n",
    "data v2 取用藥1-5 款, 刪除全0 col, 處方&針炙ignored, 文字input ignored\n",
    "\n",
    "deleted 回診,西藥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData(FILENAME):\n",
    "    data = pd.read_csv(FILENAME)\n",
    "    print(\"in ReadData\")\n",
    "    print(\"type of data:\", type(data))\n",
    "    print(f'Shape of data = ({data.shape[0]} rows, {data.shape[1]} cols).')\n",
    "    return data\n",
    "\n",
    "def SplitXY(data, data_left_bound, label_left_bound, data_right_bound=None, label_right_bound=None):\n",
    "    \"\"\"label_left_bound: 第一個藥材的col no.\"\"\"\n",
    "    # Body status: 1~3, Diagnosis: 4~7, Symptom: 11~124\n",
    "    # Prescription: 125~226\n",
    "    # split_X = list(range(0, label_left_bound))\n",
    "    # split_Y = list(range(label_left_bound, len(data.columns)))\n",
    "    if label_right_bound is None:\n",
    "        label_right_bound = len(data.columns)\n",
    "    if data_right_bound is None:\n",
    "        data_right_bound = label_left_bound\n",
    "    X = data.iloc[1:, list(range(data_left_bound, data_right_bound))]\n",
    "    y = data.iloc[1:, list(range(label_left_bound, label_right_bound))]\n",
    "    \n",
    "    # Debug\n",
    "    print(\"SplitXY:\")\n",
    "    print(f'Shape of X = ({X.shape[0]} rows, {X.shape[1]} cols). First 10 data of X:')\n",
    "    print(X.iloc[:10, :10])\n",
    "    print(f'Shape of y = ({y.shape[0]} rows, {y.shape[1]} cols). First 10 data of y:')\n",
    "    print(y.iloc[:10, :10])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def SplitNparr(original_arr: np.ndarray, train_portion: float)->tuple:\n",
    "    data_len =len(original_arr)\n",
    "    train_len = int(data_len * train_portion)\n",
    "    indices = list(range(data_len))\n",
    "    random.shuffle(indices)\n",
    "    train_idx = indices[:train_len]\n",
    "    validate_idx = indices[train_len:]\n",
    "    training_arr  = original_arr[train_idx]\n",
    "    validation_arr = original_arr[validate_idx]\n",
    "\n",
    "    return (training_arr,validation_arr)\n",
    "\n",
    "\n",
    "def Split1Df(data: pd.DataFrame,  train_size: float, random_state: int=None):\n",
    "    \"\"\"\n",
    "    Split the data into training and validation sets.\n",
    "\n",
    "    Param:\n",
    "    - data: any data\n",
    "    - train_size: Proportion of in train set.\n",
    "    - random_state: Seed \n",
    "\n",
    "    return:\n",
    "    - data_train: data for the training set.\n",
    "    - data_val: data for the validation set.\n",
    "\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "    data_len = len(data)\n",
    "    val_len = int(data_len * (1-train_size))\n",
    "    indices = list(range(data_len))\n",
    "    random.shuffle(indices)\n",
    "    val_idx = indices[:val_len]\n",
    "    train_idx = indices[val_len:]\n",
    "\n",
    "\n",
    "    data_train, data_val = data.loc[train_idx], data.loc[val_idx]\n",
    "   \n",
    "    return data_train, data_val\n",
    "\n",
    "def SplitBothXy_Df(X: pd.DataFrame, y: pd.DataFrame, train_size: float, random_state: int=None):\n",
    "    \"\"\"\n",
    "    Split the data into training and validation sets.\n",
    "\n",
    "    Param:\n",
    "    - X: Features \n",
    "    - y: Target variable\n",
    "    - train_size: Proportion of in train set.\n",
    "    - random_state: Seed \n",
    "\n",
    "    return:\n",
    "    - X_train: Features for the training set.\n",
    "    - X_val: Features for the validation set.\n",
    "    - y_train: Target variable for the training set.\n",
    "    - y_val: Target variable for the validation set.\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "    data_len = len(X)\n",
    "    val_len = int(data_len * (1-train_size))\n",
    "    indices = list(range(data_len))\n",
    "    random.shuffle(indices)\n",
    "    val_idx = indices[:val_len]\n",
    "    train_idx = indices[val_len:]\n",
    "\n",
    "\n",
    "    X_train, X_val = X.loc[train_idx], X.loc[val_idx]\n",
    "    y_train, y_val = y.loc[train_idx], y.loc[val_idx]\n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_val) == len(y_val)\n",
    "    return X_train, X_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ReadData\n",
      "type of data: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of data = (113 rows, 180 cols).\n"
     ]
    }
   ],
   "source": [
    "data_pd = ReadData(\"./simplified_data/simplified_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_medicine:  麻黃\n",
      "should be 麻黃\n",
      "chosen_medicine_idx:  167\n",
      "chosen_medicine:  甘草\n"
     ]
    }
   ],
   "source": [
    "first_medicine_idx = 100\n",
    "chosen_medicine='甘草'\n",
    "chosen_medicine_idx = None\n",
    "print(\"first_medicine: \",data_pd.columns[first_medicine_idx])\n",
    "print(\"should be 麻黃\")\n",
    "\n",
    "\n",
    "for i in range(len(data_pd.columns.tolist())):\n",
    "    if data_pd.columns.tolist()[i] == chosen_medicine:\n",
    "        chosen_medicine_idx = i\n",
    "        break\n",
    "print(\"chosen_medicine_idx: \", chosen_medicine_idx)\n",
    "print(\"chosen_medicine: \" ,data_pd.columns.tolist()[chosen_medicine_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitXY:\n",
      "Shape of X = (112 rows, 98 cols). First 10 data of X:\n",
      "    乳癌  肺癌  肝癌  腺癌  攝護腺癌  骨癌  腦瘤  肝炎  水腫  二便\n",
      "1    0   0   0   0     0   0   0   0   0   0\n",
      "2    0   0   0   0     0   0   0   0   0   0\n",
      "3    0   0   0   0     0   0   0   0   1   0\n",
      "4    0   0   0   0     0   0   0   0   0   1\n",
      "5    0   0   0   0     0   0   0   0   0   0\n",
      "6    0   0   0   0     0   0   0   0   0   0\n",
      "7    0   0   0   0     0   0   0   0   0   0\n",
      "8    0   0   0   0     0   0   0   0   0   0\n",
      "9    0   0   0   0     0   0   0   1   0   0\n",
      "10   0   0   0   0     0   0   1   0   0   0\n",
      "Shape of y = (112 rows, 1 cols). First 10 data of y:\n",
      "    甘草\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "10   0\n"
     ]
    }
   ],
   "source": [
    "# now try only by 1 mdeicine\n",
    "\n",
    "X,y = SplitXY(data_pd, data_left_bound=2, data_right_bound=first_medicine_idx, \n",
    "              label_left_bound=chosen_medicine_idx, label_right_bound=chosen_medicine_idx+1)\n",
    "X_np = X.values.astype('float64')\n",
    "y_np = y.values.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_np (112, 98)\n",
      "shape of y_np (112, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X_np\", X_np.shape)\n",
    "print(\"shape of y_np\", y_np.shape)\n",
    "input_dim = X_np.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 16)                1584      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,194\n",
      "Trainable params: 2,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense (units=16, input_shape=(98,), activation='relu'),\n",
    "    Dense (units=32, activation='relu'), \n",
    "    Dense (units=2, activation='softmax')\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 - 1s - loss: 0.6333 - accuracy: 0.6786 - 1s/epoch - 99ms/step\n",
      "Epoch 2/10\n",
      "12/12 - 0s - loss: 0.4938 - accuracy: 0.7321 - 31ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "12/12 - 0s - loss: 0.3806 - accuracy: 0.8036 - 36ms/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "12/12 - 0s - loss: 0.2929 - accuracy: 0.8839 - 40ms/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "12/12 - 0s - loss: 0.2050 - accuracy: 0.9196 - 32ms/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "12/12 - 0s - loss: 0.1464 - accuracy: 0.9375 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "12/12 - 0s - loss: 0.1025 - accuracy: 0.9464 - 40ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "12/12 - 0s - loss: 0.0812 - accuracy: 0.9643 - 40ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "12/12 - 0s - loss: 0.0659 - accuracy: 0.9821 - 34ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "12/12 - 0s - loss: 0.0579 - accuracy: 0.9821 - 35ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231e5d82580>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_np, y=y_np,\n",
    "          batch_size=10, epochs=10, shuffle=True, verbose=2)\n",
    "\n",
    "# looks like label have to be column vector..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
