{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use simplified data 1\n",
    "\n",
    "data source:\n",
    "\n",
    "data v2 取用藥1-5 款, 刪除全0 col, 處方&針炙ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData(FILENAME):\n",
    "    data = pd.read_csv(FILENAME)\n",
    "    print(\"in ReadData\")\n",
    "    print(\"type of data:\", type(data))\n",
    "    print(f'Shape of data = ({data.shape[0]} rows, {data.shape[1]} cols).')\n",
    "    return data\n",
    "\n",
    "def SplitXY(data, data_left_bound,label_left_bound):\n",
    "    \"\"\"label_left_bound: 第一個藥材的col no.\"\"\"\n",
    "    # Body status: 1~3, Diagnosis: 4~7, Symptom: 11~124\n",
    "    # Prescription: 125~226\n",
    "    # split_X = list(range(0, label_left_bound))\n",
    "    # split_Y = list(range(label_left_bound, len(data.columns)))\n",
    "    X = data.iloc[1:, list(range(data_left_bound, label_left_bound))]\n",
    "    y = data.iloc[1:, list(range(label_left_bound, len(data.columns)))]\n",
    "    # Debug\n",
    "    print(\"SplitXY:\")\n",
    "    print(f'Shape of X = ({X.shape[0]} rows, {X.shape[1]} cols). First 10 data of X:')\n",
    "    print(X.iloc[:10, :10])\n",
    "    print(f'Shape of y = ({y.shape[0]} rows, {y.shape[1]} cols). First 10 data of y:')\n",
    "    print(y.iloc[:10, :10])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ReadData\n",
      "type of data: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of data = (113 rows, 182 cols).\n"
     ]
    }
   ],
   "source": [
    "data_pd = ReadData(\"./simplified_data/simplified_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "麻黃\n",
      "Unnamed: 0    3\n",
      "炙甘草           0\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_pd.columns[102])\n",
    "# 麻黃 是第一個藥材,在第109col\n",
    "print(data_pd.iloc[0, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SplitXY:\n",
      "Shape of X = (112 rows, 101 cols). First 10 data of X:\n",
      "    炙甘草  乳癌  肺癌  肝癌  腺癌  攝護腺癌  骨癌  腦瘤  肝炎  回診\n",
      "1     0   0   0   0   0     0   0   0   0   1\n",
      "2     0   0   0   0   0     0   0   0   0   0\n",
      "3     0   0   0   0   0     0   0   0   0   0\n",
      "4     0   0   0   0   0     0   0   0   0   0\n",
      "5     0   0   0   0   0     0   0   0   0   0\n",
      "6     0   0   0   0   0     0   0   0   0   1\n",
      "7     0   0   0   0   0     0   0   0   0   0\n",
      "8     0   0   0   0   0     0   0   0   0   0\n",
      "9     0   0   0   0   0     0   0   0   1   1\n",
      "10    0   0   0   0   0     0   0   1   0   0\n",
      "Shape of y = (112 rows, 80 cols). First 10 data of y:\n",
      "    麻黃  桂枝  荊芥  防風  細辛  白芷  生薑  辛夷  柴胡  蟬蛻\n",
      "1    0   0   0   0   0   0   0   0   0   0\n",
      "2    0   0   0   0   0   0   0   0   0   0\n",
      "3    0   0   0   0   0   0   0   0   0   0\n",
      "4    0   0   0   0   0   0   0   0   0   0\n",
      "5    0   0   0   0   0   0   0   0   0   0\n",
      "6    0   0   0   0   0   0   0   0   0   0\n",
      "7    0   0   0   0   0   0   0   0   0   0\n",
      "8    0   0   0   0   0   0   0   0   0   0\n",
      "9    0   0   0   0   0   0   0   0   0   0\n",
      "10   0   0   0   0   0   0   0   0   0   0\n"
     ]
    }
   ],
   "source": [
    "X,y = SplitXY(data_pd, 1, 102)\n",
    "X_np = X.values.astype('float64')\n",
    "y_np = y.values.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_np (112, 101)\n",
      "shape of y_np (80, 112)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X_np\", X_np.shape)\n",
    "print(\"shape of y_np\", y_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 160)               16320     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 322       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,642\n",
      "Trainable params: 16,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense (units=160, input_shape=(101,), activation='relu'),\n",
    "    Dense (units=2, activation='softmax')\n",
    "])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(8960,) and logits.shape=(112, 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\taliah\\code\\ml_class\\tcm-project\\ml-tcm-nn\\ML_TCM_NN\\cnn_simplfied_data1.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/taliah/code/ml_class/tcm-project/ml-tcm-nn/ML_TCM_NN/cnn_simplfied_data1.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX_np, y\u001b[39m=\u001b[39;49my_np,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taliah/code/ml_class/tcm-project/ml-tcm-nn/ML_TCM_NN/cnn_simplfied_data1.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m112\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0cpc7ns3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\losses.py\", line 2084, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\taliah\\miniconda3\\envs\\ml2\\lib\\site-packages\\keras\\backend.py\", line 5630, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(8960,) and logits.shape=(112, 2)\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_np, y=y_np,\n",
    "          batch_size=112, epochs=10, shuffle=True, verbose=2)\n",
    "\n",
    "# looks like label have to be column vector..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
