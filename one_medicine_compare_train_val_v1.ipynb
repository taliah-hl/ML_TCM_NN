{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change to load data from load_data.py\n",
    "\n",
    "\n",
    "data source: ./simplified_data/simplified_data2.csv\n",
    "\n",
    "data source: ./simplified_data/simplified_data2.csv\n",
    "\n",
    "data 處理:\n",
    "\n",
    "data v2 刪掉所有文字input\n",
    "\n",
    "deleted 回診,西藥\n",
    "\n",
    "## train 方法:\n",
    "\n",
    ".....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import statistics\n",
    "from tabulate import tabulate\n",
    "\n",
    "# custom import \n",
    "from utility_file import my_utilities as myutil\n",
    "from utility_file import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "\n",
    "1. 決定是否要delete 少於某threshold的藥\n",
    "2. 用load_data裡的`load_data_for_n_med` load data\n",
    "3. 如只train 頭n 個藥-> set `only_train_1st_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ReadData\n",
      "type of data: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of data = (797 rows, 215 cols).\n",
      "SplitXY:\n",
      "Shape of X = (796 rows, 111 cols). First 10 data of X:\n",
      "    肺癌  胰臟癌  肝癌  腺癌  攝護腺癌  骨癌  淋巴癌  胃癌  腦瘤  肝炎\n",
      "1    0    0   0   0     0   0    0   0   0   0\n",
      "2    0    0   0   0     0   0    0   0   0   0\n",
      "3    0    0   0   0     0   0    0   0   0   0\n",
      "4    0    0   0   0     0   0    0   0   0   0\n",
      "5    0    0   0   0     0   0    0   0   0   0\n",
      "6    0    0   0   0     0   0    0   0   0   0\n",
      "7    0    0   0   0     0   0    0   0   0   0\n",
      "8    0    0   0   0     0   0    0   0   0   0\n",
      "9    0    0   0   0     0   0    0   0   0   0\n",
      "10   0    0   0   0     0   0    0   0   0   0\n",
      "Shape of y = (796 rows, 3 cols). First 10 data of y:\n",
      "    麻黃  桂枝  荊芥\n",
      "1    0   1   0\n",
      "2    0   1   0\n",
      "3    0   0   0\n",
      "4    0   1   0\n",
      "5    0   1   0\n",
      "6    0   0   0\n",
      "7    0   1   0\n",
      "8    0   1   0\n",
      "9    0   1   0\n",
      "10   0   1   0\n",
      "=======================\n",
      "\n",
      "in load_data_for_1_med_with_debug of load_data.py, random_seed= None\n",
      "after SplitXY, total number of 0, 1 in y:\n",
      "no. of 1: 489\n",
      "no. of 0: 1899\n",
      "DeleteMedicine: shape of y is (796, 3).\n",
      "in SplitBothXy_Df of load_data, len of val_idx 159\n",
      "train_X.shape:  (637, 111)\n",
      "train_y.shape:  (637, 3)\n",
      "\n",
      "debug no, of 0 and 1 in y after Split trina val\n",
      "no. of 1 in train_y: 385\n",
      "no. of 0 in train_y: 1526\n",
      "no. of 1 in val_y: 104\n",
      "no. of 0 in val_y: 373\n"
     ]
    }
   ],
   "source": [
    "del_med_under_thres = 0     # 於所有medical cases中出現次數少於此數的藥->整col 刪除\n",
    "                            # if set to 250 -> will leave 10 medicine\n",
    "\n",
    "total_med = 102\n",
    "only_train_1st_n = 3\n",
    "\n",
    "(X_np, X_val_np, train_y, val_y, \n",
    "  num_col_x, num_1_valy, num_0_valy) = load_data.load_data_for_1_med_with_debug(del_med_thres=del_med_under_thres, n=only_train_1st_n)\n",
    "\n",
    "assert(isinstance(X_np, np.ndarray))\n",
    "assert(isinstance(X_val_np, np.ndarray))\n",
    "assert(isinstance(train_y, pd.DataFrame))\n",
    "assert(isinstance(val_y, pd.DataFrame))\n",
    "assert(isinstance(num_col_x, int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values in y: 0\n",
      "Number of str values in y: 0\n",
      "Number of int values in y: 477\n",
      "Number of float values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# data type checking  you can run this if you suspect data type \n",
    "# else can skip this cell\n",
    "\n",
    "\n",
    "# myutil.print_df(val_y, \"---- y ----\")\n",
    "# print(val_y)\n",
    "# checking\n",
    "# 1. Count occurrence of na, int, float, str in y\n",
    "na_count = val_y.isna().sum().sum()\n",
    "str_count = val_y[val_y.map(type) == str].count().sum()\n",
    "int_count = val_y[val_y.map(type) == int].count().sum()\n",
    "float_count = val_y[val_y.map(type) == float].count().sum()\n",
    "\n",
    "print(f\"Number of NA values in y: {na_count}\")\n",
    "print(f\"Number of str values in y: {str_count}\")\n",
    "print(f\"Number of int values in y: {int_count}\")\n",
    "print(f\"Number of float values in y: {float_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # class_weights = compute_sample_weight(class_weight='balanced', y=train_y)\n",
    "# # class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# # print(class_weight_dict)\n",
    "\n",
    "# train_y_np = np.array(train_y)\n",
    "\n",
    "# num_labels = train_y_np.shape[1]\n",
    "# class_weight_dic = {}\n",
    "\n",
    "# for i in range(num_labels):\n",
    "#     unique_values, counts = np.unique(train_y_np[:, i], return_counts=True)\n",
    "#     value_frequency_dict = dict(zip(unique_values, counts))\n",
    "#     total = value_frequency_dict[0] + value_frequency_dict[1]\n",
    "#     class_weight_dic[i] = {0: (value_frequency_dict[1] / total), 1: 5 * (value_frequency_dict[0] / total)} \n",
    "#     # f1: 0.35\n",
    "#     # class_weight_dic[i] = {0: (total / value_frequency_dict[0]), 1: 5 * (total / value_frequency_dict[1])}\n",
    "\n",
    "# print(class_weight_dic)\n",
    "# class_weight_list = np.array(class_weight_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                1792      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,458\n",
      "Trainable params: 3,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense (units=16, input_shape=(num_col_x,), activation='relu'),\n",
    "    Dense (units=32, activation='relu'), \n",
    "    Dense (units=32, activation='relu'), \n",
    "    Dense (units=2, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "train medicine-by-medicine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing the 1 of 3 medicine: 麻黃\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "processing the 2 of 3 medicine: 桂枝\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "type of predictions val:  <class 'numpy.ndarray'>\n",
      "predictions.shape: (159, 2)\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "processing the 3 of 3 medicine: 荊芥\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "training done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_df_dict={}   # dict of df\n",
    "#loss_acc_dict={}    # dict of loss and accuracy of each medicine\n",
    "accuracy_dict={}    # dict of accuracy of each medicine\n",
    "raw_prediction_train_dict={}   # dict of raw prediction of train set\n",
    "raw_prediction_val_dict={}   # dict of raw prediction of val set\n",
    "histories={}\n",
    "\n",
    "for i in range(train_y.shape[1]):\n",
    "#for i in range(2):\n",
    "\n",
    "    chosen_col = train_y.iloc[:,i].copy()\n",
    "    assert(isinstance(chosen_col, pd.Series))\n",
    "    assert(len(chosen_col) == len(train_y))\n",
    "    print(f\"processing the {i+1} of {train_y.shape[1]} medicine: { chosen_col.name}\")\n",
    "\n",
    "    chosen_y_np = chosen_col.values.astype('float64')\n",
    "\n",
    "    y_val_chosen_col = val_y.iloc[:,i].copy()\n",
    "    assert(isinstance(y_val_chosen_col, pd.Series))\n",
    "    assert(len(y_val_chosen_col) == len(val_y))\n",
    "    #y_val_chosen_col_np = y_val_chosen_col.values.astype('float64')\n",
    "\n",
    "    \n",
    "    # Early stop\n",
    "    #early_stopping = EarlyStopping(monitor='loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "    \n",
    "    # fit model for this medicine\n",
    "    history =  model.fit(\n",
    "        x=X_np,\n",
    "        y=chosen_y_np,\n",
    "        # class_weight=class_weight_dic[i],\n",
    "        epochs=10,\n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "        #callbacks=[early_stopping]\n",
    "    )   # batch_size=32 if not specified\n",
    "    \n",
    "    # make prediction for this medicine\n",
    "    predictions_val_set = model.predict(X_val_np)\n",
    "    if(i==1):\n",
    "        print(\"type of predictions val: \" ,type(predictions_val_set))\n",
    "        print(\"predictions.shape:\", predictions_val_set.shape)\n",
    "        \n",
    "    raw_prediction_val_dict[chosen_col.name] = predictions_val_set  # save raw result np of val set to dict\n",
    "    \n",
    "\n",
    "    predictions_train_set = model.predict(X_np)   # predict against training set for diagonse overfit or underfit\n",
    "    raw_prediction_train_dict[chosen_col.name] = predictions_train_set  # save raw result np of train set to dict\n",
    "    histories[chosen_col.name] = history.history    # save history \n",
    "\n",
    "print(\"training done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.callbacks.History'>\n"
     ]
    }
   ],
   "source": [
    "print( type(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9953419e-01 4.6575195e-04]\n",
      " [9.9997371e-01 2.6214255e-05]\n",
      " [3.0542278e-01 6.9457716e-01]\n",
      " ...\n",
      " [9.9849200e-01 1.5079654e-03]\n",
      " [9.9999988e-01 7.9778538e-08]\n",
      " [1.0000000e+00 2.1376767e-08]]\n",
      "[[0.82413435 0.17586562]\n",
      " [0.49058878 0.5094112 ]\n",
      " [0.49058878 0.5094112 ]\n",
      " ...\n",
      " [0.49058878 0.5094112 ]\n",
      " [0.49058878 0.5094112 ]\n",
      " [0.49058878 0.5094112 ]]\n",
      "[[9.9999982e-01 1.1729692e-07]\n",
      " [9.9457169e-01 5.4282043e-03]\n",
      " [9.7601217e-01 2.3987820e-02]\n",
      " ...\n",
      " [8.4819311e-01 1.5180686e-01]\n",
      " [1.0000000e+00 1.9593778e-14]\n",
      " [9.9998677e-01 1.3206654e-05]]\n",
      "fooo\n"
     ]
    }
   ],
   "source": [
    "for key, arr in raw_prediction_train_dict.items():\n",
    "    print(arr)\n",
    "print(\"fooo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "1274\n",
      "[[9.9953419e-01 4.6575195e-04]\n",
      " [9.9997371e-01 2.6214255e-05]\n",
      " [3.0542278e-01 6.9457716e-01]\n",
      " ...\n",
      " [9.9849200e-01 1.5079654e-03]\n",
      " [9.9999988e-01 7.9778538e-08]\n",
      " [1.0000000e+00 2.1376767e-08]]\n",
      "[[0.82413435 0.17586562]\n",
      " [0.49058878 0.5094112 ]\n",
      " [0.49058878 0.5094112 ]\n",
      " ...\n",
      " [0.49058878 0.5094112 ]\n",
      " [0.49058878 0.5094112 ]\n",
      " [0.49058878 0.5094112 ]]\n",
      "[[9.9999982e-01 1.1729692e-07]\n",
      " [9.9457169e-01 5.4282043e-03]\n",
      " [9.7601217e-01 2.3987820e-02]\n",
      " ...\n",
      " [8.4819311e-01 1.5180686e-01]\n",
      " [1.0000000e+00 1.9593778e-14]\n",
      " [9.9998677e-01 1.3206654e-05]]\n"
     ]
    }
   ],
   "source": [
    "# simple check\n",
    "# total_zeros = np.sum(predictions_val_set == 0)\n",
    "# print(\"total no. of 0 in prediction of val\", total_zeros)\n",
    "# total_ones = np.sum(predictions_val_set == 1)\n",
    "# print(\"total no. of 1 in prediction of val\", total_ones)\n",
    "# total_zeros = np.sum(predictions_train_set == 0)\n",
    "# print(\"total no. of 0 in prediction of train\", total_zeros)\n",
    "# total_ones = np.sum(predictions_train_set == 1)\n",
    "# print(\"total no. of 1 in prediction of train\", total_ones)\n",
    "print(np.count_nonzero(predictions_val_set))\n",
    "print(np.count_nonzero(predictions_train_set))\n",
    "for key, arr in raw_prediction_train_dict.items():\n",
    "    print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal TP, FP, TN, FN for train set\n",
    "total_tp_train=0\n",
    "total_fp_train =0\n",
    "total_tn_train =0\n",
    "total_fn_train =0\n",
    "\n",
    "predicted_value_index = None\n",
    "ground_truth_index = None\n",
    "\n",
    "for key, arr in raw_prediction_train_dict.items():\n",
    "    df_tmp = pd.DataFrame(arr, columns=[\"predicted as 0\", \"predicted as 1\"])\n",
    "    df_tmp[\"predicted value\"] = np.where(df_tmp[\"predicted as 0\"] > df_tmp[\"predicted as 1\"], 0, 1)\n",
    "    col_num = train_y.columns.get_loc(key)\n",
    "    df_tmp[\"ground truth\"] = train_y.iloc[:,col_num].copy().values\n",
    "    if predicted_value_index is None:\n",
    "        predicted_value_index = df_tmp.columns.get_loc('predicted value')\n",
    "    if ground_truth_index is None:\n",
    "        ground_truth_index = df_tmp.columns.get_loc('ground truth')\n",
    "\n",
    "    total_tp_train += ((df_tmp['ground truth'] == 1) & (df_tmp['predicted value'] == 1)).sum()\n",
    "    total_fp_train += ((df_tmp['ground truth'] == 0) & (df_tmp['predicted value'] == 1)).sum()\n",
    "    total_fn_train += ((df_tmp['ground truth'] == 1) & (df_tmp['predicted value'] == 0)).sum()\n",
    "    total_tn_train += ((df_tmp['ground truth'] == 0) & (df_tmp['predicted value'] == 0)).sum()\n",
    "\n",
    "\n",
    "overall_f1_train = 2 * total_tp_train / (2 * total_tp_train + total_fp_train + total_fn_train) if (2 * total_tp_train + total_fp_train + total_fn_train) != 0 else 0\n",
    "\n",
    "train_set_acc = {}\n",
    "train_set_acc[\"TP\"]=total_tp_train\n",
    "train_set_acc[\"FP\"]=total_fp_train\n",
    "train_set_acc[\"FN\"]=total_fn_train\n",
    "train_set_acc[\"TN\"]=total_tn_train\n",
    "# no. of medical case in train set = # row in train_x * # col in train_y or val_y\n",
    "med_case_train = (X_np.shape[0] *  val_y.shape[1])\n",
    "train_set_acc[\"TP_percentage\"] = total_tp_train / med_case_train\n",
    "train_set_acc[\"FP_percentage\"] = total_fp_train / med_case_train\n",
    "train_set_acc[\"FN_percentage\"] = total_fn_train / med_case_train\n",
    "train_set_acc[\"TN_percentage\"] = total_tn_train / med_case_train\n",
    "train_set_acc[\"overall_f1\"] = overall_f1_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set_acc[\"precision\"] = total_tp_train / (total_tp_train + total_fp_train) if (total_tp_train + total_fp_train) != 0 else 0\n",
    "train_set_acc[\"recall\"] = total_tp_train / (total_tp_train + total_fn_train) if (total_tp_train + total_fn_train) != 0 else 0\n",
    "\n",
    "# precision = 判斷為true之中有多少是對的 = TP / (TP + FP) \n",
    "# recall  =  實際為true之中有多少被找到  = TP / (TP + FN) \n",
    "\n",
    "try:\n",
    "    assert((total_tp_train + total_fp_train + total_fn_train + total_tn_train) == med_case_train)\n",
    "except:\n",
    "    print(\"assertion error for calculation check of train set\")\n",
    "    print(f\"tp+fp+tn+fn={total_tp_train + total_fp_train + total_fn_train + total_tn_train} , total med case={med_case_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 345, 'FP': 213, 'FN': 40, 'TN': 1313, 'TP_percentage': 0.18053375196232338, 'FP_percentage': 0.11145996860282574, 'FN_percentage': 0.020931449502878074, 'TN_percentage': 0.6870748299319728, 'overall_f1': 0.7317073170731707, 'precision': 0.6182795698924731, 'recall': 0.8961038961038961}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+-------------------+----------------+--------------+\n",
      "|     |   predicted as 0 |   predicted as 1 |   predicted value |   ground truth | is_correct   |\n",
      "|-----+------------------+------------------+-------------------+----------------+--------------|\n",
      "|   0 |         0.996979 |      0.00302105  |                 0 |              0 | True         |\n",
      "|   1 |         0.99955  |      0.000450101 |                 0 |              0 | True         |\n",
      "|   2 |         0.999978 |      2.23361e-05 |                 0 |              0 | True         |\n",
      "|   3 |         0.818789 |      0.181211    |                 0 |              0 | True         |\n",
      "|   4 |         0.996814 |      0.00318565  |                 0 |              0 | True         |\n",
      "|   5 |         0.999977 |      2.29809e-05 |                 0 |              0 | True         |\n",
      "|   6 |         0.999989 |      1.06373e-05 |                 0 |              0 | True         |\n",
      "|   7 |         0.729643 |      0.270357    |                 0 |              0 | True         |\n",
      "|   8 |         0.999885 |      0.000115103 |                 0 |              0 | True         |\n",
      "|   9 |         0.93613  |      0.0638699   |                 0 |              0 | True         |\n",
      "|  10 |         1        |      2.73589e-19 |                 0 |              0 | True         |\n",
      "|  11 |         0.998964 |      0.00103589  |                 0 |              1 | False        |\n",
      "|  12 |         0.309717 |      0.690283    |                 1 |              0 | False        |\n",
      "|  13 |         0.992624 |      0.00737571  |                 0 |              0 | True         |\n",
      "|  14 |         0.999799 |      0.000201372 |                 0 |              1 | False        |\n",
      "|  15 |         0.964627 |      0.0353726   |                 0 |              1 | False        |\n",
      "|  16 |         1        |      1.37872e-12 |                 0 |              0 | True         |\n",
      "|  17 |         0.999355 |      0.000644476 |                 0 |              1 | False        |\n",
      "|  18 |         0.526936 |      0.473064    |                 0 |              0 | True         |\n",
      "|  19 |         0.818789 |      0.181211    |                 0 |              1 | False        |\n",
      "|  20 |         1        |      6.99717e-09 |                 0 |              0 | True         |\n",
      "|  21 |         0.859659 |      0.140341    |                 0 |              0 | True         |\n",
      "|  22 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "|  23 |         0.906388 |      0.0936124   |                 0 |              0 | True         |\n",
      "|  24 |         0.999997 |      2.73537e-06 |                 0 |              0 | True         |\n",
      "|  25 |         0.999989 |      1.07479e-05 |                 0 |              0 | True         |\n",
      "|  26 |         1        |      1.13939e-19 |                 0 |              0 | True         |\n",
      "|  27 |         0.398462 |      0.601538    |                 1 |              0 | False        |\n",
      "|  28 |         0.999834 |      0.000166108 |                 0 |              0 | True         |\n",
      "|  29 |         1        |      2.0348e-21  |                 0 |              0 | True         |\n",
      "|  30 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "|  31 |         0.999352 |      0.000648448 |                 0 |              0 | True         |\n",
      "|  32 |         0.999989 |      1.06741e-05 |                 0 |              0 | True         |\n",
      "|  33 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "|  34 |         0.512998 |      0.487002    |                 0 |              0 | True         |\n",
      "|  35 |         0.385932 |      0.614068    |                 1 |              1 | True         |\n",
      "|  36 |         0.833179 |      0.166821    |                 0 |              0 | True         |\n",
      "|  37 |         0.999715 |      0.000285181 |                 0 |              0 | True         |\n",
      "|  38 |         0.398462 |      0.601538    |                 1 |              0 | False        |\n",
      "|  39 |         0.46388  |      0.53612     |                 1 |              0 | False        |\n",
      "|  40 |         0.822029 |      0.177971    |                 0 |              0 | True         |\n",
      "|  41 |         1        |      1.11094e-11 |                 0 |              0 | True         |\n",
      "|  42 |         0.998628 |      0.00137178  |                 0 |              0 | True         |\n",
      "|  43 |         0.998681 |      0.00131907  |                 0 |              1 | False        |\n",
      "|  44 |         0.305423 |      0.694577    |                 1 |              1 | True         |\n",
      "|  45 |         0.999949 |      5.07369e-05 |                 0 |              0 | True         |\n",
      "|  46 |         0.984887 |      0.0151132   |                 0 |              0 | True         |\n",
      "|  47 |         1        |      1.79497e-07 |                 0 |              0 | True         |\n",
      "|  48 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "|  49 |         0.999994 |      5.53189e-06 |                 0 |              0 | True         |\n",
      "|  50 |         0.999345 |      0.000654951 |                 0 |              0 | True         |\n",
      "|  51 |         0.99481  |      0.00518964  |                 0 |              0 | True         |\n",
      "|  52 |         0.98727  |      0.0127301   |                 0 |              0 | True         |\n",
      "|  53 |         0.999999 |      8.7016e-07  |                 0 |              0 | True         |\n",
      "|  54 |         0.996311 |      0.00368883  |                 0 |              0 | True         |\n",
      "|  55 |         1        |      6.32766e-11 |                 0 |              0 | True         |\n",
      "|  56 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "|  57 |         1        |      8.86539e-09 |                 0 |              1 | False        |\n",
      "|  58 |         0.971124 |      0.028876    |                 0 |              0 | True         |\n",
      "|  59 |         0.571835 |      0.428165    |                 0 |              0 | True         |\n",
      "|  60 |         0.997236 |      0.00276403  |                 0 |              0 | True         |\n",
      "|  61 |         0.999792 |      0.000207815 |                 0 |              0 | True         |\n",
      "|  62 |         0.999805 |      0.000195323 |                 0 |              0 | True         |\n",
      "|  63 |         0.999991 |      8.78771e-06 |                 0 |              0 | True         |\n",
      "|  64 |         0.992265 |      0.00773536  |                 0 |              0 | True         |\n",
      "|  65 |         0.999832 |      0.000168415 |                 0 |              0 | True         |\n",
      "|  66 |         1        |      1.43778e-10 |                 0 |              0 | True         |\n",
      "|  67 |         0.713844 |      0.286156    |                 0 |              0 | True         |\n",
      "|  68 |         0.818789 |      0.181211    |                 0 |              0 | True         |\n",
      "|  69 |         0.997924 |      0.00207564  |                 0 |              1 | False        |\n",
      "|  70 |         0.999993 |      7.09409e-06 |                 0 |              0 | True         |\n",
      "|  71 |         0.999989 |      1.13792e-05 |                 0 |              0 | True         |\n",
      "|  72 |         1        |      1.11236e-07 |                 0 |              0 | True         |\n",
      "|  73 |         0.995649 |      0.0043509   |                 0 |              0 | True         |\n",
      "|  74 |         0.992288 |      0.00771237  |                 0 |              1 | False        |\n",
      "|  75 |         1        |      1.11528e-15 |                 0 |              0 | True         |\n",
      "|  76 |         0.935439 |      0.0645606   |                 0 |              1 | False        |\n",
      "|  77 |         0.999999 |      5.2801e-07  |                 0 |              0 | True         |\n",
      "|  78 |         0.991572 |      0.0084279   |                 0 |              0 | True         |\n",
      "|  79 |         0.999008 |      0.000991769 |                 0 |              0 | True         |\n",
      "|  80 |         0.999994 |      6.48183e-06 |                 0 |              1 | False        |\n",
      "|  81 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "|  82 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "|  83 |         0.325983 |      0.674017    |                 1 |              1 | True         |\n",
      "|  84 |         0.995911 |      0.00408862  |                 0 |              0 | True         |\n",
      "|  85 |         0.818789 |      0.181211    |                 0 |              0 | True         |\n",
      "|  86 |         0.999999 |      7.77997e-07 |                 0 |              1 | False        |\n",
      "|  87 |         0.999941 |      5.91249e-05 |                 0 |              0 | True         |\n",
      "|  88 |         0.940658 |      0.0593419   |                 0 |              0 | True         |\n",
      "|  89 |         0.740028 |      0.259972    |                 0 |              0 | True         |\n",
      "|  90 |         0.818789 |      0.181211    |                 0 |              0 | True         |\n",
      "|  91 |         1        |      8.30257e-09 |                 0 |              0 | True         |\n",
      "|  92 |         0.999844 |      0.000156541 |                 0 |              0 | True         |\n",
      "|  93 |         1        |      4.36541e-11 |                 0 |              0 | True         |\n",
      "|  94 |         0.996828 |      0.00317247  |                 0 |              1 | False        |\n",
      "|  95 |         0.986646 |      0.0133536   |                 0 |              0 | True         |\n",
      "|  96 |         0.998729 |      0.00127139  |                 0 |              0 | True         |\n",
      "|  97 |         1        |      9.1852e-09  |                 0 |              0 | True         |\n",
      "|  98 |         0.539854 |      0.460146    |                 0 |              1 | False        |\n",
      "|  99 |         0.869761 |      0.130239    |                 0 |              0 | True         |\n",
      "| 100 |         0.972145 |      0.0278548   |                 0 |              1 | False        |\n",
      "| 101 |         0.999983 |      1.73289e-05 |                 0 |              0 | True         |\n",
      "| 102 |         0.888777 |      0.111223    |                 0 |              0 | True         |\n",
      "| 103 |         0.894644 |      0.105355    |                 0 |              0 | True         |\n",
      "| 104 |         0.999771 |      0.00022932  |                 0 |              0 | True         |\n",
      "| 105 |         0.999999 |      1.04869e-06 |                 0 |              0 | True         |\n",
      "| 106 |         0.564826 |      0.435174    |                 0 |              0 | True         |\n",
      "| 107 |         0.384126 |      0.615874    |                 1 |              0 | False        |\n",
      "| 108 |         0.999989 |      1.05796e-05 |                 0 |              0 | True         |\n",
      "| 109 |         0.42784  |      0.572161    |                 1 |              0 | False        |\n",
      "| 110 |         0.991867 |      0.00813266  |                 0 |              1 | False        |\n",
      "| 111 |         0.998612 |      0.00138832  |                 0 |              0 | True         |\n",
      "| 112 |         1        |      1.05561e-07 |                 0 |              0 | True         |\n",
      "| 113 |         0.995693 |      0.00430696  |                 0 |              0 | True         |\n",
      "| 114 |         0.736921 |      0.263079    |                 0 |              0 | True         |\n",
      "| 115 |         0.999967 |      3.3081e-05  |                 0 |              0 | True         |\n",
      "| 116 |         0.999984 |      1.62885e-05 |                 0 |              0 | True         |\n",
      "| 117 |         0.999997 |      2.57924e-06 |                 0 |              0 | True         |\n",
      "| 118 |         0.995699 |      0.00430083  |                 0 |              0 | True         |\n",
      "| 119 |         0.999854 |      0.000146497 |                 0 |              0 | True         |\n",
      "| 120 |         0.999801 |      0.000198803 |                 0 |              0 | True         |\n",
      "| 121 |         1        |      2.20112e-09 |                 0 |              0 | True         |\n",
      "| 122 |         1        |      1.18561e-08 |                 0 |              0 | True         |\n",
      "| 123 |         0.999997 |      2.49815e-06 |                 0 |              0 | True         |\n",
      "| 124 |         0.999983 |      1.6564e-05  |                 0 |              1 | False        |\n",
      "| 125 |         1        |      2.69217e-20 |                 0 |              0 | True         |\n",
      "| 126 |         0.840422 |      0.159578    |                 0 |              0 | True         |\n",
      "| 127 |         0.997884 |      0.00211582  |                 0 |              0 | True         |\n",
      "| 128 |         0.997532 |      0.0024684   |                 0 |              0 | True         |\n",
      "| 129 |         0.999668 |      0.000331535 |                 0 |              0 | True         |\n",
      "| 130 |         0.900169 |      0.0998312   |                 0 |              0 | True         |\n",
      "| 131 |         0.998301 |      0.00169925  |                 0 |              0 | True         |\n",
      "| 132 |         0.985488 |      0.0145122   |                 0 |              0 | True         |\n",
      "| 133 |         0.926997 |      0.0730027   |                 0 |              0 | True         |\n",
      "| 134 |         1        |      7.92345e-10 |                 0 |              0 | True         |\n",
      "| 135 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "| 136 |         0.998966 |      0.00103449  |                 0 |              1 | False        |\n",
      "| 137 |         0.970877 |      0.0291225   |                 0 |              0 | True         |\n",
      "| 138 |         0.999643 |      0.000356596 |                 0 |              1 | False        |\n",
      "| 139 |         0.999912 |      8.77742e-05 |                 0 |              0 | True         |\n",
      "| 140 |         0.98389  |      0.0161104   |                 0 |              0 | True         |\n",
      "| 141 |         0.999757 |      0.000242914 |                 0 |              1 | False        |\n",
      "| 142 |         0.999564 |      0.000436464 |                 0 |              0 | True         |\n",
      "| 143 |         0.984729 |      0.0152715   |                 0 |              0 | True         |\n",
      "| 144 |         0.999967 |      3.31869e-05 |                 0 |              0 | True         |\n",
      "| 145 |         0.998314 |      0.00168628  |                 0 |              0 | True         |\n",
      "| 146 |         0.985986 |      0.0140136   |                 0 |              0 | True         |\n",
      "| 147 |         0.305423 |      0.694577    |                 1 |              0 | False        |\n",
      "| 148 |         0.949757 |      0.0502432   |                 0 |              0 | True         |\n",
      "| 149 |         0.99611  |      0.00389027  |                 0 |              0 | True         |\n",
      "| 150 |         0.930272 |      0.0697277   |                 0 |              0 | True         |\n",
      "| 151 |         0.988954 |      0.0110456   |                 0 |              0 | True         |\n",
      "| 152 |         0.999966 |      3.41053e-05 |                 0 |              1 | False        |\n",
      "| 153 |         0.818789 |      0.181211    |                 0 |              0 | True         |\n",
      "| 154 |         0.999949 |      5.13775e-05 |                 0 |              1 | False        |\n",
      "| 155 |         0.999977 |      2.30406e-05 |                 0 |              0 | True         |\n",
      "| 156 |         0.988767 |      0.0112325   |                 0 |              1 | False        |\n",
      "| 157 |         0.818789 |      0.181211    |                 0 |              0 | True         |\n",
      "| 158 |         0.899722 |      0.100278    |                 0 |              0 | True         |\n",
      "+-----+------------------+------------------+-------------------+----------------+--------------+\n",
      "+-----+------------------+------------------+-------------------+----------------+--------------+\n",
      "|     |   predicted as 0 |   predicted as 1 |   predicted value |   ground truth | is_correct   |\n",
      "|-----+------------------+------------------+-------------------+----------------+--------------|\n",
      "|   0 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|   1 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|   2 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|   3 |         0.709838 |      0.290162    |                 0 |              0 | True         |\n",
      "|   4 |         0.982614 |      0.0173861   |                 0 |              1 | False        |\n",
      "|   5 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|   6 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|   7 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|   8 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|   9 |         0.955879 |      0.0441214   |                 0 |              1 | False        |\n",
      "|  10 |         0.991461 |      0.00853959  |                 0 |              1 | False        |\n",
      "|  11 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  12 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  13 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  14 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  15 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  16 |         0.733661 |      0.266339    |                 0 |              0 | True         |\n",
      "|  17 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  18 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  19 |         0.709838 |      0.290162    |                 0 |              0 | True         |\n",
      "|  20 |         0.876329 |      0.123671    |                 0 |              0 | True         |\n",
      "|  21 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  22 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  23 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  24 |         0.99849  |      0.00150946  |                 0 |              1 | False        |\n",
      "|  25 |         0.570222 |      0.429778    |                 0 |              1 | False        |\n",
      "|  26 |         0.999965 |      3.4523e-05  |                 0 |              0 | True         |\n",
      "|  27 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  28 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  29 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  30 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  31 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  32 |         0.997084 |      0.0029162   |                 0 |              0 | True         |\n",
      "|  33 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  34 |         0.517329 |      0.482671    |                 0 |              1 | False        |\n",
      "|  35 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  36 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  37 |         0.566782 |      0.433218    |                 0 |              0 | True         |\n",
      "|  38 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  39 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  40 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  41 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  42 |         0.831062 |      0.168938    |                 0 |              0 | True         |\n",
      "|  43 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  44 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  45 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  46 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  47 |         0.999946 |      5.39958e-05 |                 0 |              0 | True         |\n",
      "|  48 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  49 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  50 |         0.977924 |      0.0220759   |                 0 |              0 | True         |\n",
      "|  51 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  52 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  53 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  54 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  55 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  56 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  57 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  58 |         0.774241 |      0.225759    |                 0 |              0 | True         |\n",
      "|  59 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  60 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  61 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  62 |         0.972693 |      0.0273073   |                 0 |              0 | True         |\n",
      "|  63 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  64 |         0.966159 |      0.0338407   |                 0 |              0 | True         |\n",
      "|  65 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  66 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  67 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  68 |         0.709838 |      0.290162    |                 0 |              0 | True         |\n",
      "|  69 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  70 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  71 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  72 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  73 |         0.898333 |      0.101667    |                 0 |              0 | True         |\n",
      "|  74 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  75 |         0.999991 |      8.94567e-06 |                 0 |              0 | True         |\n",
      "|  76 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  77 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  78 |         0.98326  |      0.0167399   |                 0 |              0 | True         |\n",
      "|  79 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  80 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  81 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  82 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  83 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  84 |         0.608936 |      0.391064    |                 0 |              1 | False        |\n",
      "|  85 |         0.709838 |      0.290162    |                 0 |              0 | True         |\n",
      "|  86 |         0.556029 |      0.443971    |                 0 |              1 | False        |\n",
      "|  87 |         0.665713 |      0.334287    |                 0 |              1 | False        |\n",
      "|  88 |         0.970692 |      0.0293083   |                 0 |              1 | False        |\n",
      "|  89 |         0.854431 |      0.145569    |                 0 |              0 | True         |\n",
      "|  90 |         0.709838 |      0.290162    |                 0 |              0 | True         |\n",
      "|  91 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  92 |         0.963423 |      0.0365774   |                 0 |              0 | True         |\n",
      "|  93 |         0.972157 |      0.0278434   |                 0 |              0 | True         |\n",
      "|  94 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "|  95 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  96 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  97 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  98 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "|  99 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 100 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 101 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 102 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 103 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 104 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 105 |         0.822867 |      0.177133    |                 0 |              0 | True         |\n",
      "| 106 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 107 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 108 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 109 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 110 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 111 |         0.930155 |      0.0698453   |                 0 |              0 | True         |\n",
      "| 112 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 113 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 114 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 115 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 116 |         0.999843 |      0.000157266 |                 0 |              1 | False        |\n",
      "| 117 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 118 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 119 |         0.871152 |      0.128848    |                 0 |              1 | False        |\n",
      "| 120 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 121 |         0.999682 |      0.000317819 |                 0 |              0 | True         |\n",
      "| 122 |         0.995634 |      0.00436617  |                 0 |              0 | True         |\n",
      "| 123 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 124 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 125 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 126 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 127 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 128 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 129 |         0.991246 |      0.00875441  |                 0 |              0 | True         |\n",
      "| 130 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 131 |         0.907107 |      0.0928926   |                 0 |              0 | True         |\n",
      "| 132 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 133 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 134 |         0.730876 |      0.269124    |                 0 |              0 | True         |\n",
      "| 135 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 136 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 137 |         0.767613 |      0.232387    |                 0 |              0 | True         |\n",
      "| 138 |         0.512668 |      0.487332    |                 0 |              1 | False        |\n",
      "| 139 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 140 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 141 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 142 |         0.992395 |      0.00760475  |                 0 |              0 | True         |\n",
      "| 143 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 144 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 145 |         0.979437 |      0.020563    |                 0 |              1 | False        |\n",
      "| 146 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 147 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 148 |         0.490589 |      0.509411    |                 1 |              1 | True         |\n",
      "| 149 |         0.61009  |      0.38991     |                 0 |              0 | True         |\n",
      "| 150 |         0.948577 |      0.0514229   |                 0 |              0 | True         |\n",
      "| 151 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 152 |         0.778043 |      0.221957    |                 0 |              1 | False        |\n",
      "| 153 |         0.709838 |      0.290162    |                 0 |              0 | True         |\n",
      "| 154 |         0.958294 |      0.0417058   |                 0 |              1 | False        |\n",
      "| 155 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 156 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "| 157 |         0.709838 |      0.290162    |                 0 |              1 | False        |\n",
      "| 158 |         0.490589 |      0.509411    |                 1 |              0 | False        |\n",
      "+-----+------------------+------------------+-------------------+----------------+--------------+\n",
      "+-----+------------------+------------------+-------------------+----------------+--------------+\n",
      "|     |   predicted as 0 |   predicted as 1 |   predicted value |   ground truth | is_correct   |\n",
      "|-----+------------------+------------------+-------------------+----------------+--------------|\n",
      "|   0 |         0.999999 |      1.31911e-06 |                 0 |              0 | True         |\n",
      "|   1 |         0.999996 |      4.35308e-06 |                 0 |              0 | True         |\n",
      "|   2 |         0.905839 |      0.0941612   |                 0 |              0 | True         |\n",
      "|   3 |         0.988252 |      0.0117483   |                 0 |              0 | True         |\n",
      "|   4 |         0.999996 |      4.08779e-06 |                 0 |              0 | True         |\n",
      "|   5 |         0.999993 |      7.26272e-06 |                 0 |              0 | True         |\n",
      "|   6 |         1        |      2.69368e-13 |                 0 |              0 | True         |\n",
      "|   7 |         0.999406 |      0.000593678 |                 0 |              0 | True         |\n",
      "|   8 |         0.979238 |      0.0207624   |                 0 |              0 | True         |\n",
      "|   9 |         0.99911  |      0.000890133 |                 0 |              0 | True         |\n",
      "|  10 |         1        |      2.11048e-11 |                 0 |              0 | True         |\n",
      "|  11 |         0.999901 |      9.926e-05   |                 0 |              0 | True         |\n",
      "|  12 |         0.999971 |      2.86474e-05 |                 0 |              0 | True         |\n",
      "|  13 |         0.999984 |      1.61836e-05 |                 0 |              0 | True         |\n",
      "|  14 |         0.903155 |      0.0968447   |                 0 |              0 | True         |\n",
      "|  15 |         0.999925 |      7.52293e-05 |                 0 |              0 | True         |\n",
      "|  16 |         0.99995  |      5.0223e-05  |                 0 |              1 | False        |\n",
      "|  17 |         0.999872 |      0.000128255 |                 0 |              0 | True         |\n",
      "|  18 |         0.999791 |      0.000209113 |                 0 |              0 | True         |\n",
      "|  19 |         0.988252 |      0.0117483   |                 0 |              1 | False        |\n",
      "|  20 |         1        |      1.01606e-08 |                 0 |              0 | True         |\n",
      "|  21 |         0.996179 |      0.00382071  |                 0 |              0 | True         |\n",
      "|  22 |         0.950867 |      0.049133    |                 0 |              0 | True         |\n",
      "|  23 |         0.994406 |      0.00559417  |                 0 |              0 | True         |\n",
      "|  24 |         0.999182 |      0.000817947 |                 0 |              0 | True         |\n",
      "|  25 |         1        |      4.81896e-08 |                 0 |              0 | True         |\n",
      "|  26 |         1        |      6.46918e-09 |                 0 |              0 | True         |\n",
      "|  27 |         0.995106 |      0.0048938   |                 0 |              0 | True         |\n",
      "|  28 |         0.996079 |      0.00392051  |                 0 |              0 | True         |\n",
      "|  29 |         1        |      6.03792e-11 |                 0 |              0 | True         |\n",
      "|  30 |         0.996378 |      0.00362223  |                 0 |              0 | True         |\n",
      "|  31 |         0.999994 |      6.36303e-06 |                 0 |              0 | True         |\n",
      "|  32 |         0.999996 |      4.28787e-06 |                 0 |              0 | True         |\n",
      "|  33 |         0.9913   |      0.00869954  |                 0 |              0 | True         |\n",
      "|  34 |         0.999999 |      1.12772e-06 |                 0 |              0 | True         |\n",
      "|  35 |         0.955501 |      0.0444991   |                 0 |              0 | True         |\n",
      "|  36 |         1        |      2.68794e-07 |                 0 |              0 | True         |\n",
      "|  37 |         1        |      1.55802e-07 |                 0 |              0 | True         |\n",
      "|  38 |         0.995106 |      0.0048938   |                 0 |              1 | False        |\n",
      "|  39 |         0.999935 |      6.51441e-05 |                 0 |              0 | True         |\n",
      "|  40 |         0.994566 |      0.00543372  |                 0 |              0 | True         |\n",
      "|  41 |         0.999939 |      6.0674e-05  |                 0 |              0 | True         |\n",
      "|  42 |         1        |      4.28474e-08 |                 0 |              0 | True         |\n",
      "|  43 |         1        |      8.541e-08   |                 0 |              0 | True         |\n",
      "|  44 |         0.863301 |      0.136699    |                 0 |              0 | True         |\n",
      "|  45 |         0.999822 |      0.000178207 |                 0 |              1 | False        |\n",
      "|  46 |         0.998962 |      0.00103768  |                 0 |              0 | True         |\n",
      "|  47 |         1        |      3.94437e-09 |                 0 |              0 | True         |\n",
      "|  48 |         0.998283 |      0.00171719  |                 0 |              0 | True         |\n",
      "|  49 |         0.999449 |      0.000550601 |                 0 |              0 | True         |\n",
      "|  50 |         0.999999 |      1.33377e-06 |                 0 |              0 | True         |\n",
      "|  51 |         0.999966 |      3.35833e-05 |                 0 |              0 | True         |\n",
      "|  52 |         0.999695 |      0.000305201 |                 0 |              0 | True         |\n",
      "|  53 |         0.999993 |      7.25776e-06 |                 0 |              0 | True         |\n",
      "|  54 |         0.999214 |      0.00078609  |                 0 |              0 | True         |\n",
      "|  55 |         0.998954 |      0.00104568  |                 0 |              0 | True         |\n",
      "|  56 |         0.82157  |      0.17843     |                 0 |              0 | True         |\n",
      "|  57 |         1        |      6.30691e-13 |                 0 |              0 | True         |\n",
      "|  58 |         0.99994  |      5.95314e-05 |                 0 |              0 | True         |\n",
      "|  59 |         0.999848 |      0.0001516   |                 0 |              0 | True         |\n",
      "|  60 |         0.999932 |      6.78328e-05 |                 0 |              0 | True         |\n",
      "|  61 |         0.98287  |      0.0171298   |                 0 |              1 | False        |\n",
      "|  62 |         0.999998 |      1.5419e-06  |                 0 |              0 | True         |\n",
      "|  63 |         1        |      5.21728e-11 |                 0 |              0 | True         |\n",
      "|  64 |         0.999982 |      1.75449e-05 |                 0 |              0 | True         |\n",
      "|  65 |         1        |      1.67731e-09 |                 0 |              0 | True         |\n",
      "|  66 |         0.99997  |      3.04263e-05 |                 0 |              0 | True         |\n",
      "|  67 |         0.972115 |      0.0278852   |                 0 |              0 | True         |\n",
      "|  68 |         0.988252 |      0.0117483   |                 0 |              0 | True         |\n",
      "|  69 |         1        |      2.26224e-08 |                 0 |              0 | True         |\n",
      "|  70 |         0.999982 |      1.77557e-05 |                 0 |              0 | True         |\n",
      "|  71 |         0.999995 |      4.63288e-06 |                 0 |              0 | True         |\n",
      "|  72 |         1        |      9.01975e-09 |                 0 |              0 | True         |\n",
      "|  73 |         0.999599 |      0.000400621 |                 0 |              0 | True         |\n",
      "|  74 |         0.999603 |      0.000397058 |                 0 |              0 | True         |\n",
      "|  75 |         1        |      1.47835e-08 |                 0 |              0 | True         |\n",
      "|  76 |         0.97902  |      0.0209799   |                 0 |              0 | True         |\n",
      "|  77 |         0.999578 |      0.000422237 |                 0 |              0 | True         |\n",
      "|  78 |         0.999987 |      1.27306e-05 |                 0 |              0 | True         |\n",
      "|  79 |         0.999952 |      4.76343e-05 |                 0 |              0 | True         |\n",
      "|  80 |         0.999938 |      6.23904e-05 |                 0 |              0 | True         |\n",
      "|  81 |         0.999934 |      6.55846e-05 |                 0 |              0 | True         |\n",
      "|  82 |         0.976342 |      0.0236577   |                 0 |              0 | True         |\n",
      "|  83 |         0.997954 |      0.00204583  |                 0 |              0 | True         |\n",
      "|  84 |         0.999995 |      4.47628e-06 |                 0 |              0 | True         |\n",
      "|  85 |         0.988252 |      0.0117483   |                 0 |              0 | True         |\n",
      "|  86 |         0.99683  |      0.0031697   |                 0 |              0 | True         |\n",
      "|  87 |         0.999677 |      0.000323007 |                 0 |              0 | True         |\n",
      "|  88 |         0.999962 |      3.82023e-05 |                 0 |              0 | True         |\n",
      "|  89 |         0.999937 |      6.31984e-05 |                 0 |              0 | True         |\n",
      "|  90 |         0.988252 |      0.0117483   |                 0 |              0 | True         |\n",
      "|  91 |         1        |      3.70911e-08 |                 0 |              0 | True         |\n",
      "|  92 |         0.999992 |      8.02172e-06 |                 0 |              0 | True         |\n",
      "|  93 |         1        |      1.04178e-10 |                 0 |              0 | True         |\n",
      "|  94 |         0.999293 |      0.000707214 |                 0 |              0 | True         |\n",
      "|  95 |         0.999861 |      0.000138527 |                 0 |              0 | True         |\n",
      "|  96 |         1        |      5.10202e-09 |                 0 |              0 | True         |\n",
      "|  97 |         0.999999 |      4.91807e-07 |                 0 |              0 | True         |\n",
      "|  98 |         0.998801 |      0.00119963  |                 0 |              0 | True         |\n",
      "|  99 |         0.956983 |      0.0430165   |                 0 |              0 | True         |\n",
      "| 100 |         1        |      5.7508e-08  |                 0 |              0 | True         |\n",
      "| 101 |         0.998086 |      0.00191345  |                 0 |              0 | True         |\n",
      "| 102 |         0.99997  |      2.94691e-05 |                 0 |              0 | True         |\n",
      "| 103 |         1        |      6.26684e-09 |                 0 |              0 | True         |\n",
      "| 104 |         0.99629  |      0.00371     |                 0 |              0 | True         |\n",
      "| 105 |         0.999272 |      0.000727697 |                 0 |              0 | True         |\n",
      "| 106 |         0.971647 |      0.028353    |                 0 |              0 | True         |\n",
      "| 107 |         0.999997 |      2.66943e-06 |                 0 |              0 | True         |\n",
      "| 108 |         1        |      4.12988e-07 |                 0 |              0 | True         |\n",
      "| 109 |         0.999966 |      3.4093e-05  |                 0 |              0 | True         |\n",
      "| 110 |         0.897689 |      0.102311    |                 0 |              0 | True         |\n",
      "| 111 |         0.999999 |      1.42067e-06 |                 0 |              0 | True         |\n",
      "| 112 |         0.993133 |      0.00686705  |                 0 |              0 | True         |\n",
      "| 113 |         0.999973 |      2.72321e-05 |                 0 |              0 | True         |\n",
      "| 114 |         0.990499 |      0.00950138  |                 0 |              0 | True         |\n",
      "| 115 |         1        |      8.98616e-09 |                 0 |              0 | True         |\n",
      "| 116 |         1        |      1.00259e-08 |                 0 |              0 | True         |\n",
      "| 117 |         0.999787 |      0.000213149 |                 0 |              0 | True         |\n",
      "| 118 |         0.999962 |      3.76776e-05 |                 0 |              0 | True         |\n",
      "| 119 |         1        |      2.55512e-09 |                 0 |              0 | True         |\n",
      "| 120 |         0.997898 |      0.00210169  |                 0 |              0 | True         |\n",
      "| 121 |         1        |      2.53659e-07 |                 0 |              0 | True         |\n",
      "| 122 |         1        |      4.00982e-10 |                 0 |              0 | True         |\n",
      "| 123 |         1        |      1.94905e-14 |                 0 |              0 | True         |\n",
      "| 124 |         0.947976 |      0.0520242   |                 0 |              0 | True         |\n",
      "| 125 |         1        |      4.02053e-18 |                 0 |              0 | True         |\n",
      "| 126 |         0.999999 |      5.8231e-07  |                 0 |              0 | True         |\n",
      "| 127 |         0.999989 |      1.12858e-05 |                 0 |              0 | True         |\n",
      "| 128 |         0.999997 |      2.8019e-06  |                 0 |              0 | True         |\n",
      "| 129 |         1        |      5.67289e-08 |                 0 |              0 | True         |\n",
      "| 130 |         0.999667 |      0.00033336  |                 0 |              0 | True         |\n",
      "| 131 |         0.999973 |      2.64923e-05 |                 0 |              0 | True         |\n",
      "| 132 |         0.999644 |      0.000356236 |                 0 |              0 | True         |\n",
      "| 133 |         0.999845 |      0.00015535  |                 0 |              0 | True         |\n",
      "| 134 |         0.999498 |      0.000501758 |                 0 |              0 | True         |\n",
      "| 135 |         0.999896 |      0.00010424  |                 0 |              0 | True         |\n",
      "| 136 |         0.999999 |      9.23061e-07 |                 0 |              0 | True         |\n",
      "| 137 |         0.999984 |      1.58138e-05 |                 0 |              0 | True         |\n",
      "| 138 |         0.999999 |      4.95709e-07 |                 0 |              0 | True         |\n",
      "| 139 |         0.976234 |      0.0237663   |                 0 |              0 | True         |\n",
      "| 140 |         0.999995 |      4.70916e-06 |                 0 |              0 | True         |\n",
      "| 141 |         0.999998 |      1.71562e-06 |                 0 |              0 | True         |\n",
      "| 142 |         0.999997 |      3.2708e-06  |                 0 |              0 | True         |\n",
      "| 143 |         0.999977 |      2.27297e-05 |                 0 |              0 | True         |\n",
      "| 144 |         0.510633 |      0.489367    |                 0 |              0 | True         |\n",
      "| 145 |         1        |      3.11218e-08 |                 0 |              1 | False        |\n",
      "| 146 |         0.994939 |      0.00506122  |                 0 |              1 | False        |\n",
      "| 147 |         0.702669 |      0.297331    |                 0 |              0 | True         |\n",
      "| 148 |         0.999994 |      5.73082e-06 |                 0 |              0 | True         |\n",
      "| 149 |         0.999211 |      0.00078861  |                 0 |              0 | True         |\n",
      "| 150 |         0.996504 |      0.00349573  |                 0 |              0 | True         |\n",
      "| 151 |         0.969135 |      0.0308648   |                 0 |              0 | True         |\n",
      "| 152 |         1        |      7.69275e-09 |                 0 |              1 | False        |\n",
      "| 153 |         0.988252 |      0.0117483   |                 0 |              0 | True         |\n",
      "| 154 |         1        |      1.99798e-07 |                 0 |              0 | True         |\n",
      "| 155 |         1        |      8.74756e-09 |                 0 |              0 | True         |\n",
      "| 156 |         0.999805 |      0.000195496 |                 0 |              0 | True         |\n",
      "| 157 |         0.988252 |      0.0117483   |                 0 |              0 | True         |\n",
      "| 158 |         0.485324 |      0.514676    |                 1 |              0 | False        |\n",
      "+-----+------------------+------------------+-------------------+----------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# put prediction into df for val set\n",
    "\n",
    "for key, arr in raw_prediction_val_dict.items():\n",
    "    df_predictions = pd.DataFrame(arr, columns=[\"predicted as 0\", \"predicted as 1\"])\n",
    "    df_predictions[\"predicted value\"] = np.where(df_predictions[\"predicted as 0\"] > df_predictions[\"predicted as 1\"], 0, 1)\n",
    "    col_num = val_y.columns.get_loc(key)\n",
    "    df_predictions[\"ground truth\"] = val_y.iloc[:,col_num].copy().values\n",
    "    df_predictions[\"is_correct\"] = df_predictions[\"predicted value\"] == df_predictions[\"ground truth\"]\n",
    "    accuracy = df_predictions[\"is_correct\"].mean()\n",
    "    accuracy_dict[key] = accuracy  \n",
    "    result_df_dict[key] = df_predictions\n",
    "    result_df_dict[key] = df_predictions\n",
    "    print(tabulate(df_predictions, headers='keys',tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in for loop of result_df_dict\n",
      "processing : 麻黃 ....\n",
      "TP of 麻黃: 3\n",
      "FP of 麻黃: 15\n",
      "FN of 麻黃: 23\n",
      "TN of 麻黃: 118\n",
      "f1_score of 麻黃: 0.13636363636363635\n",
      "total tp now is: 3\n",
      "total fp now is: 15\n",
      "total fn now is: 23\n",
      "total tn now is: 118\n",
      "in for loop of result_df_dict\n",
      "processing : 桂枝 ....\n",
      "TP of 桂枝: 53\n",
      "FP of 桂枝: 55\n",
      "FN of 桂枝: 17\n",
      "TN of 桂枝: 34\n",
      "f1_score of 桂枝: 0.5955056179775281\n",
      "total tp now is: 56\n",
      "total fp now is: 70\n",
      "total fn now is: 40\n",
      "total tn now is: 152\n",
      "in for loop of result_df_dict\n",
      "processing : 荊芥 ....\n",
      "TP of 荊芥: 0\n",
      "FP of 荊芥: 1\n",
      "FN of 荊芥: 8\n",
      "TN of 荊芥: 150\n",
      "f1_score of 荊芥: 0.0\n",
      "total tp now is: 56\n",
      "total fp now is: 71\n",
      "total fn now is: 48\n",
      "total tn now is: 302\n",
      " \n",
      "*****   end of for loop   *****\n",
      "\n",
      "now doing calculation checking...\n",
      "checking passed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted_value_index = None\n",
    "ground_truth_index = None\n",
    "\n",
    "acc_each_med={}\n",
    "total_tp=0\n",
    "total_fp=0\n",
    "total_fn=0\n",
    "total_tn=0\n",
    "\n",
    "# df.columns.tolist()= pick list of column names\n",
    "\n",
    "for i in train_y.columns.tolist(): # build empty dict for holding TP, FP, FN, TN, accuracy, f1_score of each medicine\n",
    "    acc_each_med[i]={\"TP\": None, \"FP\": None, \"FN\": None, \"TN\": None, \"accuracy\": None, \"f1_score\": None}\n",
    "\n",
    "# calculate f1 score of for each medicine\n",
    "\n",
    "for key, df in result_df_dict.items():\n",
    "    # create 'TP/FP/TN/TN/FN' column\n",
    "\n",
    "    if predicted_value_index is None:\n",
    "        predicted_value_index = df.columns.get_loc('predicted value')\n",
    "    if ground_truth_index is None:\n",
    "        ground_truth_index = df.columns.get_loc('ground truth')\n",
    "\n",
    "\n",
    "    df['TP/FP/TN/TN/FN'] = df.apply(lambda row: 'TP' if ( row.iloc[predicted_value_index] and row.iloc[ground_truth_index] ) else \n",
    "                                 ('FP' if (row.iloc[predicted_value_index]  and (not row.iloc[ground_truth_index] )) else \n",
    "                                  ('FN' if (( not row.iloc[predicted_value_index] ) and row.iloc[ground_truth_index] ) else \n",
    "                                   ( 'TN' if ((not row.iloc[predicted_value_index]) and (not row.iloc[ground_truth_index]) ) else 'UN'))), axis=1)\n",
    "\n",
    "    # count occurrences of 'TP', 'FP', 'FN', and 'TN' of *this medicine*\n",
    "    counts = df['TP/FP/TN/TN/FN'].value_counts()\n",
    "    # get number of 'TP', 'FP', 'FN', and 'TN'\n",
    "    num_tp = counts.get('TP', 0)\n",
    "    num_fp = counts.get('FP', 0)\n",
    "    num_fn = counts.get('FN', 0)\n",
    "    num_tn = counts.get('TN', 0)\n",
    "\n",
    "    f1_score = 2 * num_tp / (2 * num_tp + num_fp + num_fn) if (2 * num_tp + num_fp + num_fn) > 0 else 0\n",
    "    acc_each_med[key][\"TP\"] = num_tp\n",
    "    acc_each_med[key][\"FP\"] = num_fp\n",
    "    acc_each_med[key][\"FN\"] = num_fn\n",
    "    acc_each_med[key][\"TN\"] = num_tn\n",
    "    acc_each_med[key][\"accuracy\"] = accuracy_dict[key].item()\n",
    "    acc_each_med[key][\"f1_score\"] = f1_score\n",
    "\n",
    "    total_tp += num_tp\n",
    "    total_fp += num_fp\n",
    "    total_fn += num_fn\n",
    "    total_tn += num_tn\n",
    "\n",
    "    ### debug messages\n",
    "    print(\"in for loop of result_df_dict\")\n",
    "    print(f\"processing : {key} ....\")\n",
    "    print(f\"TP of {key}: {num_tp}\", sep=\"\\t\")\n",
    "    print(f\"FP of {key}: {num_fp}\", sep=\"\\t\")\n",
    "    print(f\"FN of {key}: {num_fn}\", sep=\"\\t\")\n",
    "    print(f\"TN of {key}: {num_tn}\", sep=\"\\t\")\n",
    "    print(f\"f1_score of {key}: {f1_score}\")\n",
    "    print(f\"total tp now is: {total_tp}\"  , sep=\"\\t\")\n",
    "    print(f\"total fp now is: {total_fp}\"  , sep=\"\\t\")\n",
    "    print(f\"total fn now is: {total_fn}\"  , sep=\"\\t\")\n",
    "    print(f\"total tn now is: {total_tn}\"  , sep=\"\\t\")\n",
    "\n",
    "overall_f1 = 2 * total_tp / (2 * total_tp + total_fp + total_fn) if (2 * total_tp + total_fp + total_fn) > 0 else 0\n",
    "total_med_case =  len(val_y)* val_y.shape[1]\n",
    "print(\" \\n*****   end of for loop   *****\\n\")\n",
    "print(\"now doing calculation checking...\")\n",
    "mean_accuracy = statistics.mean(accuracy_dict.values())\n",
    "acc_each_med[\"overall\"]={}\n",
    "acc_each_med[\"overall\"][\"TP\"] = total_tp\n",
    "acc_each_med[\"overall\"][\"FP\"] = total_fp\n",
    "acc_each_med[\"overall\"][\"FN\"] = total_fn\n",
    "acc_each_med[\"overall\"][\"TN\"] = total_tn\n",
    "acc_each_med[\"overall\"][\"TP_percentage\"] ={total_tp/total_med_case}\n",
    "acc_each_med[\"overall\"][\"FP_percentage\"] ={total_fp/total_med_case}\n",
    "acc_each_med[\"overall\"][\"FN_percentage\"] ={total_fn/total_med_case}\n",
    "acc_each_med[\"overall\"][\"TN_percentage\"] ={total_tn/total_med_case}\n",
    "acc_each_med[\"overall\"][\"f1_score\"]=overall_f1\n",
    "acc_each_med[\"overall\"][\"mean_accuracy\"]=mean_accuracy\n",
    "acc_each_med[\"overall\"][\"precision\"] = total_tp / (total_tp + total_fp) if (total_tp + total_fp) != 0 else 0\n",
    "acc_each_med[\"overall\"][\"recall\"] = total_tp / (total_tp + total_fn) if (total_tp + total_fn) != 0 else 0\n",
    "\n",
    "\n",
    "try:\n",
    "    assert((total_tp + total_fp + total_fn + total_tn) == total_med_case)\n",
    "    assert((total_tp + total_fn)== num_1_valy)  # TP+FN=all 1 in val_y\n",
    "    assert((total_fp + total_tn)== num_0_valy)  # TN+FP=all 0 in val_y\n",
    "    \n",
    "except:\n",
    "    print(\"wrong calculation!\")\n",
    "    print(f\"otal_tp + total_fp + total_fn + total_tn= {total_tp + total_fp + total_fn + total_tn}\", sep=\"\\t\")\n",
    "    print(f\"total_med_case= {total_med_case}\")\n",
    "    print(f\"total_tp + total_fn= {total_tp + total_fn}\", sep=\"\\t\")\n",
    "    print(f\"num_1_valy= {num_1_valy}\")\n",
    "    print(f\"total_fp + total_tn= {total_fp + total_tn}\", sep=\"\\t\")\n",
    "    print(f\"num_0_valy= {num_0_valy}\")\n",
    "else:\n",
    "    print(\"checking passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tp: 56, \t percentage = 0.11740041928721175\n",
      "total fp: 71, \t percentage = 0.1488469601677149\n",
      "total fn: 48, \t percentage = 0.10062893081761007\n",
      "total tn: 302, \t percentage = 0.6331236897274634\n",
      "overall f1 score: 0.48484848484848486\n",
      "mean accuracy of all medicine:  0.750524109014675\n",
      "precision:  0.4409448818897638\n",
      "recall:  0.5384615384615384\n",
      "{'麻黃': {'TP': 3, 'FP': 15, 'FN': 23, 'TN': 118, 'accuracy': 0.7610062893081762, 'f1_score': 0.13636363636363635}, '桂枝': {'TP': 53, 'FP': 55, 'FN': 17, 'TN': 34, 'accuracy': 0.5471698113207547, 'f1_score': 0.5955056179775281}, '荊芥': {'TP': 0, 'FP': 1, 'FN': 8, 'TN': 150, 'accuracy': 0.9433962264150944, 'f1_score': 0.0}, 'overall': {'TP': 56, 'FP': 71, 'FN': 48, 'TN': 302, 'TP_percentage': {0.11740041928721175}, 'FP_percentage': {0.1488469601677149}, 'FN_percentage': {0.10062893081761007}, 'TN_percentage': {0.6331236897274634}, 'f1_score': 0.48484848484848486, 'mean_accuracy': 0.750524109014675, 'precision': 0.4409448818897638, 'recall': 0.5384615384615384}}\n",
      "-------   ---------   --------\n",
      "-----  training set accuracy  -----\n",
      "{'TP': 345, 'FP': 213, 'FN': 40, 'TN': 1313, 'TP_percentage': 0.18053375196232338, 'FP_percentage': 0.11145996860282574, 'FN_percentage': 0.020931449502878074, 'TN_percentage': 0.6870748299319728, 'overall_f1': 0.7317073170731707, 'precision': 0.6182795698924731, 'recall': 0.8961038961038961}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"total tp: {total_tp}, \\t percentage = {total_tp/total_med_case}\" )\n",
    "print(f\"total fp: {total_fp}, \\t percentage = {total_fp/total_med_case}\" )\n",
    "print(f\"total fn: {total_fn}, \\t percentage = {total_fn/total_med_case}\" )\n",
    "print(f\"total tn: {total_tn}, \\t percentage = {total_tn/total_med_case}\" )\n",
    "print(f\"overall f1 score: {overall_f1}\")\n",
    "print(\"mean accuracy of all medicine: \", mean_accuracy)\n",
    "print(\"precision: \",acc_each_med[\"overall\"][\"precision\"])\n",
    "print(\"recall: \", acc_each_med[\"overall\"][\"recall\"])\n",
    "print(acc_each_med)         # can't use json.dumps as there are np.int64\n",
    "# precision = 判斷為true之中有多少是對的 = TP / (TP + FP) \n",
    "# recall  =  實際為true之中有多少被找到  = TP / (TP + FN)\n",
    "print(\"-----------------------\\n-----  training set accuracy  -----\")\n",
    "print(train_set_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tp: 56, \t percentage = 0.11740041928721175\n",
      "total fp: 71, \t percentage = 0.1488469601677149\n",
      "total fn: 48, \t percentage = 0.10062893081761007\n",
      "total tn: 302, \t percentage = 0.6331236897274634\n",
      "overall f1 score: 0.48484848484848486\n",
      "mean accuracy of all medicine:  0.750524109014675\n",
      "precision:  0.4409448818897638\n",
      "recall:  0.5384615384615384\n",
      "{'麻黃': {'TP': 3, 'FP': 15, 'FN': 23, 'TN': 118, 'accuracy': 0.7610062893081762, 'f1_score': 0.13636363636363635}, '桂枝': {'TP': 53, 'FP': 55, 'FN': 17, 'TN': 34, 'accuracy': 0.5471698113207547, 'f1_score': 0.5955056179775281}, '荊芥': {'TP': 0, 'FP': 1, 'FN': 8, 'TN': 150, 'accuracy': 0.9433962264150944, 'f1_score': 0.0}, 'overall': {'TP': 56, 'FP': 71, 'FN': 48, 'TN': 302, 'TP_percentage': {0.11740041928721175}, 'FP_percentage': {0.1488469601677149}, 'FN_percentage': {0.10062893081761007}, 'TN_percentage': {0.6331236897274634}, 'f1_score': 0.48484848484848486, 'mean_accuracy': 0.750524109014675, 'precision': 0.4409448818897638, 'recall': 0.5384615384615384}}\n",
      "-------   ---------   --------\n",
      "-----  training set accuracy  -----\n",
      "{'TP': 345, 'FP': 213, 'FN': 40, 'TN': 1313, 'TP_percentage': 0.18053375196232338, 'FP_percentage': 0.11145996860282574, 'FN_percentage': 0.020931449502878074, 'TN_percentage': 0.6870748299319728, 'overall_f1': 0.7317073170731707, 'precision': 0.6182795698924731, 'recall': 0.8961038961038961}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"total tp: {total_tp}, \\t percentage = {total_tp/total_med_case}\" )\n",
    "print(f\"total fp: {total_fp}, \\t percentage = {total_fp/total_med_case}\" )\n",
    "print(f\"total fn: {total_fn}, \\t percentage = {total_fn/total_med_case}\" )\n",
    "print(f\"total tn: {total_tn}, \\t percentage = {total_tn/total_med_case}\" )\n",
    "print(f\"overall f1 score: {overall_f1}\")\n",
    "print(\"mean accuracy of all medicine: \", mean_accuracy)\n",
    "print(\"precision: \",acc_each_med[\"overall\"][\"precision\"])\n",
    "print(\"recall: \", acc_each_med[\"overall\"][\"recall\"])\n",
    "print(acc_each_med)         # can't use json.dumps as there are np.int64\n",
    "# precision = 判斷為true之中有多少是對的 = TP / (TP + FP) \n",
    "# recall  =  實際為true之中有多少被找到  = TP / (TP + FN)\n",
    "print(\"-----------------------\\n-----  training set accuracy  -----\")\n",
    "print(train_set_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path_suffix = \"each_med_csv\"   # type the dir for you to remember where u save the result\n",
    "for key, df in result_df_dict.items():\n",
    "    print(f\"DataFrame for {key}:\")\n",
    "    myutil.print_df(df)\n",
    "    myutil.df_to_csv(df, save_path=(\"./result/\"+file_path_suffix), file_prefix=key)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_each_med saved to ./result/1_med_accuracy/accuracy_each_med_4.txt\n"
     ]
    }
   ],
   "source": [
    "# save f1_score and TP/FP/TN/TN/FN\n",
    "\n",
    "spec_str = \"model layer: 16-32-32-2, epoch=10, batch_size=32,  activation=relu, num_med:3, del_med_under_thres=0\"\n",
    "# need to type this spec str each time to record the result\n",
    "\n",
    "file_path=\"./result/1_med_accuracy\"\n",
    "myutil.dict_to_txt(acc_each_med, save_path=file_path, \n",
    "                   file_prefix=\"accuracy_each_med\",\n",
    "                   textbox=spec_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
